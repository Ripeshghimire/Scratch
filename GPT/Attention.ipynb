{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Attention mechanism the text generating decoder part of the network can acesss all input token selectively this mean that some input tokens are more important than others for generating \n",
    "a given output token \n",
    "This means that some input toekns are more importaant than others for genrating a given output token .\n",
    "\n",
    "self in self attention refers to the mechanism ability to compute attention weights by relating different positions within a single input sequence . \n",
    "Learns the relationship amd dependencies between various parts of the input itself, such as sequence to sequence model where the attention might be between an input sequence and \n",
    "output sequence\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5500, 0.8700, 0.6600])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "attention_scores = torch.empty(inputs.shape[0])\n",
    "for i,x_i in enumerate(inputs):\n",
    "    attention_scores[i] = torch.dot(x_i,query)\n",
    "print(attention_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attentiong weights tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "sum is  tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attention_weights_tmp = attention_scores / attention_scores.sum()\n",
    "print(\"attentiong weights\",attention_weights_tmp)\n",
    "print(\"sum is \",attention_weights_tmp.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention weights  tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "sum tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "attention_weights_naive = softmax_naive(attention_scores)\n",
    "print(\"attention weights \",attention_weights_naive)\n",
    "print(\"sum\",attention_weights_naive.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "sum tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "attention_weights_softmax = torch.softmax(attention_scores,dim=0)\n",
    "print(\"Attention weights\",attention_weights_softmax)\n",
    "print(\"sum\",attention_weights_softmax.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self,d_model:int,h:int,dropout:float):\n",
    "        self.d_model = d_model\n",
    "        self. h = h \n",
    "        self.dropout = nn.Dropout()\n",
    "        self.d_k = d_model // h \n",
    "        self.w_query = nn.Linear(d_model,d_model)\n",
    "        self.w_key = nn.Linear(d_model,d_model)\n",
    "        self.w_value = nn.Linear(d_model,d_model)\n",
    "        self.w_output = nn.Linear(d_model,d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    @staticmethod\n",
    "    def attention(self,q,k,v,mask):\n",
    "        query = self.w_query(q) \n",
    "        key = self.w_key(k)    \n",
    "        value = self.w_value(v)\n",
    "\n",
    "        query  = query.view(query.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

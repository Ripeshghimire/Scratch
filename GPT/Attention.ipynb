{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Attention mechanism the text generating decoder part of the network can acesss all input token selectively this mean that some input tokens are more important than others for generating \n",
    "a given output token \n",
    "This means that some input toekns are more importaant than others for genrating a given output token .\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self,d_model:int,h:int,dropout:float):\n",
    "        self.d_model = d_model\n",
    "        self. h = h \n",
    "        self.dropout = nn.Dropout()\n",
    "        self.d_k = d_model // h \n",
    "        self.w_query = nn.Linear(d_model,d_model)\n",
    "        self.w_key = nn.Linear(d_model,d_model)\n",
    "        self.w_value = nn.Linear(d_model,d_model)\n",
    "        self.w_output = nn.Linear(d_model,d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    @staticmethod\n",
    "    def attention(self,q,k,v,mask):\n",
    "        query = self.w_query(q) \n",
    "        key = self.w_key(k)    \n",
    "        value = self.w_value(v)\n",
    "\n",
    "        query  = query.view(query.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of characters 20480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization \n",
    "with open(\"verdict.txt\",'r') as file:\n",
    "    file = file.read()\n",
    "\n",
    "print(\"Total no of characters\", len (file))\n",
    "file[:100]\n",
    "#our goal is to  tokenize 20479 characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "text = \"Hello, How are you? My name is Ripesh Ghimire? Are you doinge well? Lets talk shall we \"\n",
    "result = re.split(r'(\\s)',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4649\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', file)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1162\n"
     ]
    }
   ],
   "source": [
    "#Now we convert the token into token id \n",
    "all_words = sorted(list(set(preprocessed)))\n",
    "all_words.extend([\"<|unk|>\",\"<|endoftext|>\"])\n",
    "vocab_size = len(all_words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the given tokens into token-ids\n",
    "vocab = {token:integer for integer,token in enumerate(all_words)}\n",
    "last_items = list(vocab.items())[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizer:\n",
    "    def __init__(self,vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self,text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids \n",
    "    def decode(self,ids):\n",
    "        text = \"\".join([self.int_to_str[i]for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text) #E\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SimpleTokenizer(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding special context tokens \n",
    "'''\n",
    "as we can see we applied simple tokenizer ti a passage from a training set In this section we will modify this tokenizer to handle unknown words\n",
    "usage and addition of special context tokens that can enhance a model's understanding of context or other relevant information in the text. \n",
    "Thes special tokens can include markers for unknown words and document boundaries \n",
    "\n",
    "we will modify the vocabulary and toknizer we implemeneted in the previous section, Simple TokenizerV2 to support new token <|unk|> and <|end of text |>\n",
    "\n",
    "why do you we add this tokens? \n",
    "so we add these tokens so we can know the new words that were not part of the training adata and thus not part of the existing vocabulary.  we add end of text token to know that we can user to separate two unrelated text sources\n",
    "\n",
    "'''\n",
    "class SimpleTokenizerV2:\n",
    "    def __init__(self,vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self,text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids \n",
    "    def decode(self,ids):\n",
    "        text = \"\".join([self.int_to_str[i]for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text) #E\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello do you like tea?<|endoftext|>In the sunlit terraces ot the palace \n"
     ]
    }
   ],
   "source": [
    "text1 = \"Hello do you like tea?\"\n",
    "text2 = \"In the sunlit terraces ot the palace \"\n",
    "text = \"<|endoftext|>\".join((text1,text2))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Byte Pair Encoding \n",
    "'''\n",
    "IT BUILDS IT vocabulary by iteratively mergin frequent characters into subwords and frequent subwords into words.\n",
    "For example: BPE start with adding all individual single characters to its vocabulary (\"a\",\"b\") IN the next stage, it merges characters combinations that frequently occur together with subwords. For\n",
    "example d and e may be merge into the word \"de\" which is common in many English words like \"define\" \"depend\" \"made\" and \"hiddden \". The merges are determined by frequency cut off \n",
    "'''\n",
    "\n",
    "import tiktoken\n",
    "encoder = tiktoken.encoding_for_model(\"gpt-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How are you'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.decode(encoder.encode(\"How are you\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "DATA SAMPLING WITH A SLIDING WINDOW \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken \n",
    "with open(\"verdict.txt\",'r',encoding=\"utf-8\") as f:\n",
    "    text = f.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My name is Ripesh ghimire \"\n",
    "encoded_text = encoder.encode(text)\n",
    "encoded_text\n",
    "context_size = 4\n",
    "tarrget_size = context_size +1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "enc_text = tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5145"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[:context_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[290, 4920, 2241, 287]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[290, 4920, 2241, 287, 257]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----------> 4920\n",
      "[290, 4920] ----------> 2241\n",
      "[290, 4920, 2241] ----------> 287\n",
      "[290, 4920, 2241, 287] ----------> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,context_size+1):\n",
    "    context = enc_sample[:i] #process all the context based on the loop where the loop slices all the element are the there for sampling \n",
    "    desired  = enc_sample[i] #starts the loop with 1 index because the if we start from 0 there is will a empty list pointing at the first element\n",
    "\n",
    "    print(context,\"---------->\",desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ---------->  established\n",
      " and established ---------->  himself\n",
      " and established himself ---------->  in\n",
      " and established himself in ---------->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,context_size+1):\n",
    "    context = enc_sample[:i] #process all the context based on the loop where the loop slices all the element are the there for sampling \n",
    "    desired  = enc_sample[i] #starts the loop with 1 index because the if we start from 0 there is will a empty list pointing at the first element\n",
    "\n",
    "    print(tokenizer.decode(context),\"---------->\",tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self,text,tokenizer,max_length,stride):\n",
    "            self.tokenizer = tokenizer\n",
    "            self.input_ids = []\n",
    "            self.target_ids = []\n",
    "            token_ids = tokenizer.encode(text)\n",
    "\n",
    "            for i in range(0,len(token_ids)- max_length,stride):\n",
    "                  input_chunk = token_ids[i:i+max_length]\n",
    "                  target_chunk = token_ids[i+1:i+max_length]\n",
    "                  self.input_ids.append(input_chunk)\n",
    "                  self.target_ids.append(target_chunk)\n",
    "    def __len__(self):\n",
    "          return len(self.input_ids)\n",
    "    def __getitem__(self,idx):\n",
    "          return self.input_ids[idx],self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loader_v1(txt,batch_size = 4 ,max_length = 256,stride=128,shuffle=True,drop_last=True):\n",
    "    tokenizer= tiktoken.get_encoding('gpt2')\n",
    "    dataset = GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
    "    dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=drop_last)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('verdict.txt','r',encoding='utf-8') as file : \n",
    "    raw_text = file.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([   40,  1807, 10899, 15632,   922,   568,  1049,   284]), tensor([ 367, 3619, 2138,  438, 5891,  340, 5975, 3285]), tensor([2885,  402,  257, 2016, 1576,  373,  284,  326]), tensor([1464,  271, 7026,  257,  438,  645,  502,   11])], [tensor([ 367, 3619, 2138,  438, 5891,  340, 5975, 3285]), tensor([2885,  402,  257, 2016, 1576,  373,  284,  326]), tensor([1464,  271, 7026,  257,  438,  645,  502,   11])]]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_loader_v1(txt = raw_text,batch_size=8,max_length=4,stride=4,shuffle=False)\n",
    "data_itre = iter(dataloader)\n",
    "first_batch = next(data_itre)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([  287,   465,   550,    11, 27075,  2241,    64, 41976]),\n",
       "  tensor([  262, 13476,  5710,  6405,    11,   287,   319,    13]),\n",
       "  tensor([6001,   11,  465,  257,  290,  257,  262,  357]),\n",
       "  tensor([  286,   339, 12036,  5527,  4920,  4489, 34686, 10915])],\n",
       " [tensor([  262, 13476,  5710,  6405,    11,   287,   319,    13]),\n",
       "  tensor([6001,   11,  465,  257,  290,  257,  262,  357]),\n",
       "  tensor([  286,   339, 12036,  5527,  4920,  4489, 34686, 10915])]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_batch = next(data_itre)\n",
    "second_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(100)\n",
    "input_ids = torch.tensor([2,3,3,5])\n",
    "vocab_size = 6 \n",
    "output_dim = 3\n",
    "embedding_layer = torch.nn.Embedding(vocab_size,output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1268,  1.3564, -0.0247],\n",
      "        [-0.8466,  0.0293, -0.5721],\n",
      "        [-1.2546,  0.0486,  0.2753],\n",
      "        [-2.1550, -0.7116,  0.0575],\n",
      "        [ 0.6263, -1.7736, -0.2205],\n",
      "        [ 2.7467, -1.0480,  1.1239]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2546,  0.0486,  0.2753],\n",
       "        [-2.1550, -0.7116,  0.0575],\n",
       "        [-2.1550, -0.7116,  0.0575],\n",
       "        [ 2.7467, -1.0480,  1.1239]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"verdict.txt\",'r',encoding='utf-8') as file :\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 256 \n",
    "vocab_size = 50256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size,output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4 \n",
    "dataloader = create_loader_v1(txt =text,batch_size=8,max_length=max_length,stride=max_length,shuffle=False)\n",
    "data_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as pprint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1807</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10899</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15632</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">922</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">568</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1049</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">284</span><span style=\"font-weight: bold\">])</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">367</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3619</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2138</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">438</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5891</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5975</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3285</span><span style=\"font-weight: bold\">])</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2885</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">402</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2016</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1576</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">373</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">284</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">326</span><span style=\"font-weight: bold\">])</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1464</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">271</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7026</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">438</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">645</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">502</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">])</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m   \u001b[1;36m40\u001b[0m,  \u001b[1;36m1807\u001b[0m, \u001b[1;36m10899\u001b[0m, \u001b[1;36m15632\u001b[0m,   \u001b[1;36m922\u001b[0m,   \u001b[1;36m568\u001b[0m,  \u001b[1;36m1049\u001b[0m,   \u001b[1;36m284\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m367\u001b[0m, \u001b[1;36m3619\u001b[0m, \u001b[1;36m2138\u001b[0m,  \u001b[1;36m438\u001b[0m, \u001b[1;36m5891\u001b[0m,  \u001b[1;36m340\u001b[0m, \u001b[1;36m5975\u001b[0m, \u001b[1;36m3285\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2885\u001b[0m,  \u001b[1;36m402\u001b[0m,  \u001b[1;36m257\u001b[0m, \u001b[1;36m2016\u001b[0m, \u001b[1;36m1576\u001b[0m,  \u001b[1;36m373\u001b[0m,  \u001b[1;36m284\u001b[0m,  \u001b[1;36m326\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1464\u001b[0m,  \u001b[1;36m271\u001b[0m, \u001b[1;36m7026\u001b[0m,  \u001b[1;36m257\u001b[0m,  \u001b[1;36m438\u001b[0m,  \u001b[1;36m645\u001b[0m,  \u001b[1;36m502\u001b[0m,   \u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">367</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3619</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2138</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">438</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5891</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5975</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3285</span><span style=\"font-weight: bold\">])</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2885</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">402</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2016</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1576</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">373</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">284</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">326</span><span style=\"font-weight: bold\">])</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1464</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">271</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7026</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">438</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">645</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">502</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">])</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m367\u001b[0m, \u001b[1;36m3619\u001b[0m, \u001b[1;36m2138\u001b[0m,  \u001b[1;36m438\u001b[0m, \u001b[1;36m5891\u001b[0m,  \u001b[1;36m340\u001b[0m, \u001b[1;36m5975\u001b[0m, \u001b[1;36m3285\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2885\u001b[0m,  \u001b[1;36m402\u001b[0m,  \u001b[1;36m257\u001b[0m, \u001b[1;36m2016\u001b[0m, \u001b[1;36m1576\u001b[0m,  \u001b[1;36m373\u001b[0m,  \u001b[1;36m284\u001b[0m,  \u001b[1;36m326\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1464\u001b[0m,  \u001b[1;36m271\u001b[0m, \u001b[1;36m7026\u001b[0m,  \u001b[1;36m257\u001b[0m,  \u001b[1;36m438\u001b[0m,  \u001b[1;36m645\u001b[0m,  \u001b[1;36m502\u001b[0m,   \u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs,target = next(data_iter)\n",
    "pprint(inputs)\n",
    "pprint(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10-4,1):\n",
    "    input_ids = input_ids[1:4]\n",
    "    output_ids = output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [0,1,2,3,4,5,6]\n",
    "ids[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import tiktoken\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self,text,tokenizer,max_length,stride):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids =[]\n",
    "        self.output_ids =[]\n",
    "        token_ids = tokenizer.encode(text)\n",
    "        #Ensure sequence are of same length \n",
    "        for i in range(0,len(token_ids) - max_length,stride):\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            output_chunk = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(input_chunk)\n",
    "            self.output_ids.append(output_chunk)\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        __len__: Tells the DataLoader how many samples are in the dataset.\n",
    "        '''\n",
    "        return len(self.input_ids)\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        The __getitem__ function retrieves a specific sample from the dataset based on an index. This is used by the DataLoader to:\n",
    "\n",
    "        Fetch individual samples.\n",
    "\n",
    "        Construct batches (by calling __getitem__ multiple times).\n",
    "        7. Key Points\n",
    "        __len__: Tells the DataLoader how many samples are in the dataset.\n",
    "\n",
    "        __getitem__: Retrieves a specific sample (input-output pair) by index.\n",
    "\n",
    "        These functions are required for the DataLoader to work with your dataset.\n",
    "        '''\n",
    "        return torch.tensor(self.input_ids[index]),torch.tensor(self.output_ids[index])\n",
    "    \n",
    "\n",
    "def create_loader_v1(text,batch_size=4,max_length = 256,stride = 128,shuffle=True,drop_last = True):\n",
    "    tokenizer = tiktoken.get_encoding('gpt2') \n",
    "    dataset = GPTDataset(text,tokenizer,max_length,stride)\n",
    "    dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=drop_last)\n",
    "    return dataloader\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">token_ids <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">367</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2885</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1464</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1807</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3619</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">402</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">271</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10899</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2138</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7026</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15632</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">438</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2016</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">922</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5891</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1576</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">438</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">568</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">373</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">645</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1049</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5975</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">284</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">502</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">284</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3285</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">326</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "token_ids \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m   \u001b[1;36m40\u001b[0m,   \u001b[1;36m367\u001b[0m,  \u001b[1;36m2885\u001b[0m,  \u001b[1;36m1464\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m1807\u001b[0m,  \u001b[1;36m3619\u001b[0m,   \u001b[1;36m402\u001b[0m,   \u001b[1;36m271\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m10899\u001b[0m,  \u001b[1;36m2138\u001b[0m,   \u001b[1;36m257\u001b[0m,  \u001b[1;36m7026\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m15632\u001b[0m,   \u001b[1;36m438\u001b[0m,  \u001b[1;36m2016\u001b[0m,   \u001b[1;36m257\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m  \u001b[1;36m922\u001b[0m,  \u001b[1;36m5891\u001b[0m,  \u001b[1;36m1576\u001b[0m,   \u001b[1;36m438\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m  \u001b[1;36m568\u001b[0m,   \u001b[1;36m340\u001b[0m,   \u001b[1;36m373\u001b[0m,   \u001b[1;36m645\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m1049\u001b[0m,  \u001b[1;36m5975\u001b[0m,   \u001b[1;36m284\u001b[0m,   \u001b[1;36m502\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m  \u001b[1;36m284\u001b[0m,  \u001b[1;36m3285\u001b[0m,   \u001b[1;36m326\u001b[0m,    \u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">batch_size,max_length\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "batch_size,max_length\n",
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with open(\"verdict.txt\",'r',encoding='utf-8') as file :\n",
    "    raw_text= file.read()\n",
    "\n",
    "output_dim = 256\n",
    "vocab_size = 50527\n",
    "token_embedding_layer = nn.Embedding(vocab_size,output_dim)\n",
    "\n",
    "max_length = 4\n",
    "\n",
    "datloader = create_loader_v1(raw_text,batch_size=8,max_length=max_length,shuffle=False,stride=max_length)\n",
    "data_iter = iter(datloader)\n",
    "inputs,target = next(data_iter)\n",
    "pprint(\"token_ids\",inputs)\n",
    "pprint(\"batch_size,max_length\",inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">batch_size,max_length, embedding layer dimension\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "batch_size,max_length, embedding layer dimension\n",
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m256\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_layer = token_embedding_layer(inputs)\n",
    "pprint(\"batch_size,max_length, embedding layer dimension\",embedding_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m256\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length,output_dim)\n",
    "pos_embedding =  pos_embedding_layer(torch.arange(context_length))\n",
    "pprint(pos_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m256\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_embedding = embedding_layer + pos_embedding\n",
    "pprint(input_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“As part of the input processing pipeline, input text is first broken up into individual tokens. These tokens are then converted into token IDs using a vocabulary. The token IDs are converted into embedding vectors to which positional embeddings of a similar size are added, resulting in input embeddings that are used as input for the main LLM layers.”\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''“As part of the input processing pipeline, input text is first broken up into individual tokens. These tokens are then converted into token IDs using a vocabulary. The token IDs are converted into embedding vectors to which positional embeddings of a similar size are added, resulting in input embeddings that are used as input for the main LLM layers.”\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

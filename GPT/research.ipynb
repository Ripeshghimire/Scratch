{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\":50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"embd_dim\": 768,\n",
    "    \"n_heads\" : 12,\n",
    "    \"n_layers\" : 12,\n",
    "    \"drop_rate\" : 0.1,\n",
    "    \"qkv_bias\" : False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "text = \"Every effort moves you\"\n",
    "text1 = \"Every days hold a \"\n",
    "batch = []\n",
    "batch.append(torch.tensor(tokenizer.encode(text)))\n",
    "batch.append(torch.tensor(tokenizer.encode(text1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([6109, 3626, 6100,  345]), tensor([6109, 1528, 1745,  257,  220])]\n"
     ]
    }
   ],
   "source": [
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,x):\n",
    "         return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (y, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m([y_gelu, y_relu], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGELU\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRELU\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, i)  \u001b[38;5;66;03m# Create subplot\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Plot x vs. q   \u001b[39;00m\n\u001b[1;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Activation Function\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Add title\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Label for x-axis\u001b[39;00m\n",
      "File \u001b[0;32m~/coding/ResearchPaper/env/lib/python3.11/site-packages/matplotlib/pyplot.py:3794\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3786\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3788\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3793\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m   3796\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[1;32m   3797\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[1;32m   3798\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m   3799\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3800\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gca' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input tensor\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "# Compute activations\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"RELU\"]), 1):\n",
    "    plt.subplot(1, 2, i)  # Create subplot\n",
    "    plt.plot(x,y)  # Plot x vs. q   \n",
    "    plt.title(f\"{label} Activation Function\")  # Add title\n",
    "    plt.xlabel(\"x\")  # Label for x-axis\n",
    "    plt.ylabel(f\"{label}(x)\")  # Label for y-axis\n",
    "    plt.grid(True)  # Add grid\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "nn.GELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of characters 20479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization \n",
    "with open(\"verdict.txt\",'r') as file:\n",
    "    file = file.read()\n",
    "\n",
    "print(\"Total no of characters\", len (file))\n",
    "file[:100]\n",
    "#our goal is to tokenize 20479 characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "text = \"Hello, How are you? My name is Ripesh Ghimire? Are you doinge well? Lets talk shall we \"\n",
    "result = re.split(r'(\\s)',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4649\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', file)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1161\n"
     ]
    }
   ],
   "source": [
    "#Now we convert the token into token id \n",
    "all_words = sorted(list(set(preprocessed)))\n",
    "all_words.extend([\"<|unk|>\",\"<|endoftext|>\"])\n",
    "vocab_size = len(all_words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the given tokens into token-ids\n",
    "vocab = {token:integer for integer,token in enumerate(all_words)}\n",
    "ast_items = list(vocab.items())[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizer:\n",
    "    def __init__(self,vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self,text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids \n",
    "    def decode(self,ids):\n",
    "        text = \"\".join([self.int_to_str[i]for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text) #E\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SimpleTokenizer(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding special context tokens \n",
    "'''\n",
    "as we can see we applied simple tokenizer ti a passage from a training set In this section we will modify this tokenizer to handle unknown words\n",
    "usage and addition of special context tokens that can enhance a model's understanding of context or other relevant information in the text. \n",
    "Thes special tokens can include markers for unknown words and document boundaries \n",
    "\n",
    "we will modify the vocabulary and toknizer we implemeneted in the previous section, Simple TokenizerV2 to support new token <|unk|> and <|end of text |>\n",
    "\n",
    "why do you we add this tokens? \n",
    "so we add these tokens so we can know the new words that were not part of the training adata and thus not part of the existing vocabulary.  we add end of text token to know that we can user to separate two unrelated text sources\n",
    "\n",
    "'''\n",
    "class SimpleTokenizerV2:\n",
    "    def __init__(self,vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self,text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids \n",
    "    def decode(self,ids):\n",
    "        text = \"\".join([self.int_to_str[i]for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text) #E\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello do you like tea?<|endoftext|>In the sunlit terraces ot the palace \n"
     ]
    }
   ],
   "source": [
    "text1 = \"Hello do you like tea?\"\n",
    "text2 = \"In the sunlit terraces ot the palace \"\n",
    "text = \"<|endoftext|>\".join((text1,text2))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SimpleTokenizerV2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer1 \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleTokenizerV2\u001b[49m(vocab)\n\u001b[1;32m      2\u001b[0m tokenizer1\u001b[38;5;241m.\u001b[39mencode(text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SimpleTokenizerV2' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer1 = SimpleTokenizerV2(vocab)\n",
    "tokenizer1.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer1\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(tokenizer\u001b[38;5;241m.\u001b[39mencode(text))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer1' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer1.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Byte Pair Encoding \n",
    "'''\n",
    "IT BUILDS IT vocabulary by iteratively mergin frequent characters into subwords and frequent subwords into words.\n",
    "For example: BPE start with adding all individual single characters to its vocabulary (\"a\",\"b\") IN the next stage, it merges characters combinations that frequently occur together with subwords. For\n",
    "example d and e may be merge into the word \"de\" which is common in many English words like \"define\" \"depend\" \"made\" and \"hiddden \". The merges are determined by frequency cut off \n",
    "'''\n",
    "\n",
    "import tiktoken\n",
    "encoder = tiktoken.encoding_for_model(\"gpt-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32298, 20483, 23, 3134, 30924, 30924, 30924, 30924, 30924, 86, 389, 345, 220]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.encode(\"HO00000867678678678678678w are you \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How are you'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.decode(encoder.encode(\"How are you\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "DATA SAMPLING WITH A SLIDING WINDOW \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken \n",
    "with open(\"verdict.txt\",'r',encoding=\"utf-8\") as f:\n",
    "    text = f.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "enc_text = tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5145"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[290, 4920, 2241, 287]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4920, 2241, 287, 257]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----------> 4920\n",
      "[290, 4920] ----------> 2241\n",
      "[290, 4920, 2241] ----------> 287\n",
      "[290, 4920, 2241, 287] ----------> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired  = enc_sample[i]\n",
    "    print(context,\"---------->\",desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

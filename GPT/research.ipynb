{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of characters 20480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization \n",
    "with open(\"verdict.txt\",'r') as file:\n",
    "    file = file.read()\n",
    "\n",
    "print(\"Total no of characters\", len (file))\n",
    "file[:100]\n",
    "#our goal is to  tokenize 20479 characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "text = \"Hello, How are you? My name is Ripesh Ghimire? Are you doinge well? Lets talk shall we \"\n",
    "result = re.split(r'(\\s)',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4649\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', file)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1162\n"
     ]
    }
   ],
   "source": [
    "#Now we convert the token into token id \n",
    "all_words = sorted(list(set(preprocessed)))\n",
    "all_words.extend([\"<|unk|>\",\"<|endoftext|>\"])\n",
    "vocab_size = len(all_words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the given tokens into token-ids\n",
    "vocab = {token:integer for integer,token in enumerate(all_words)}\n",
    "last_items = list(vocab.items())[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizer:\n",
    "    def __init__(self,vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self,text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids \n",
    "    def decode(self,ids):\n",
    "        text = \"\".join([self.int_to_str[i]for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text) #E\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SimpleTokenizer(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding special context tokens \n",
    "'''\n",
    "as we can see we applied simple tokenizer ti a passage from a training set In this section we will modify this tokenizer to handle unknown words\n",
    "usage and addition of special context tokens that can enhance a model's understanding of context or other relevant information in the text. \n",
    "Thes special tokens can include markers for unknown words and document boundaries \n",
    "\n",
    "we will modify the vocabulary and toknizer we implemeneted in the previous section, Simple TokenizerV2 to support new token <|unk|> and <|end of text |>\n",
    "\n",
    "why do you we add this tokens? \n",
    "so we add these tokens so we can know the new words that were not part of the training adata and thus not part of the existing vocabulary.  we add end of text token to know that we can user to separate two unrelated text sources\n",
    "\n",
    "'''\n",
    "class SimpleTokenizerV2:\n",
    "    def __init__(self,vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self,text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids \n",
    "    def decode(self,ids):\n",
    "        text = \"\".join([self.int_to_str[i]for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text) #E\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello do you like tea?<|endoftext|>In the sunlit terraces ot the palace \n"
     ]
    }
   ],
   "source": [
    "text1 = \"Hello do you like tea?\"\n",
    "text2 = \"In the sunlit terraces ot the palace \"\n",
    "text = \"<|endoftext|>\".join((text1,text2))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Byte Pair Encoding \n",
    "'''\n",
    "IT BUILDS IT vocabulary by iteratively mergin frequent characters into subwords and frequent subwords into words.\n",
    "For example: BPE start with adding all individual single characters to its vocabulary (\"a\",\"b\") IN the next stage, it merges characters combinations that frequently occur together with subwords. For\n",
    "example d and e may be merge into the word \"de\" which is common in many English words like \"define\" \"depend\" \"made\" and \"hiddden \". The merges are determined by frequency cut off \n",
    "'''\n",
    "\n",
    "import tiktoken\n",
    "encoder = tiktoken.encoding_for_model(\"gpt-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How are you'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.decode(encoder.encode(\"How are you\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "DATA SAMPLING WITH A SLIDING WINDOW \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken \n",
    "with open(\"verdict.txt\",'r',encoding=\"utf-8\") as f:\n",
    "    text = f.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "enc_text = tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5145"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[:context_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[290, 4920, 2241, 287]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[290, 4920, 2241, 287, 257]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----------> 4920\n",
      "[290, 4920] ----------> 2241\n",
      "[290, 4920, 2241] ----------> 287\n",
      "[290, 4920, 2241, 287] ----------> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,context_size+1):\n",
    "    context = enc_sample[:i] #process all the context based on the loop where the loop slices all the element are the there for sampling \n",
    "    desired  = enc_sample[i] #starts the loop with 1 index because the if we start from 0 there is will a empty list pointing at the first element\n",
    "\n",
    "    print(context,\"---------->\",desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ---------->  established\n",
      " and established ---------->  himself\n",
      " and established himself ---------->  in\n",
      " and established himself in ---------->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,context_size+1):\n",
    "    context = enc_sample[:i] #process all the context based on the loop where the loop slices all the element are the there for sampling \n",
    "    desired  = enc_sample[i] #starts the loop with 1 index because the if we start from 0 there is will a empty list pointing at the first element\n",
    "\n",
    "    print(tokenizer.decode(context),\"---------->\",tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self,text,tokenizer,max_length,stride):\n",
    "            self.tokenizer = tokenizer\n",
    "            self.input_ids = []\n",
    "            self.target_ids = []\n",
    "            token_ids = tokenizer.encode(text)\n",
    "\n",
    "            for i in range(0,len(token_ids)- max_length,stride):\n",
    "                  input_chunk = token_ids[i:i+max_length]\n",
    "                  target_chunk = token_ids[i+1:i+max_length]\n",
    "                  self.input_ids.append(input_chunk)\n",
    "                  self.target_ids.append(target_chunk)\n",
    "    def __len__(self):\n",
    "          return len(self.input_ids)\n",
    "    def __getitem__(self,idx):\n",
    "          return self.input_ids[idx],self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loader_v1(txt,batch_size = 4 ,max_length = 256,stride=128,shuffle=True,drop_last=True):\n",
    "    tokenizer= tiktoken.get_encoding('gpt2')\n",
    "    dataset = GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
    "    dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=drop_last)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('verdict.txt','r',encoding='utf-8') as file : \n",
    "    raw_text = file.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([   40,  1807, 10899, 15632,   922,   568,  1049,   284]), tensor([ 367, 3619, 2138,  438, 5891,  340, 5975, 3285]), tensor([2885,  402,  257, 2016, 1576,  373,  284,  326]), tensor([1464,  271, 7026,  257,  438,  645,  502,   11])], [tensor([ 367, 3619, 2138,  438, 5891,  340, 5975, 3285]), tensor([2885,  402,  257, 2016, 1576,  373,  284,  326]), tensor([1464,  271, 7026,  257,  438,  645,  502,   11])]]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_loader_v1(txt = raw_text,batch_size=8,max_length=4,stride=4,shuffle=False)\n",
    "data_itre = iter(dataloader)\n",
    "first_batch = next(data_itre)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([  287,   465,   550,    11, 27075,  2241,    64, 41976]),\n",
       "  tensor([  262, 13476,  5710,  6405,    11,   287,   319,    13]),\n",
       "  tensor([6001,   11,  465,  257,  290,  257,  262,  357]),\n",
       "  tensor([  286,   339, 12036,  5527,  4920,  4489, 34686, 10915])],\n",
       " [tensor([  262, 13476,  5710,  6405,    11,   287,   319,    13]),\n",
       "  tensor([6001,   11,  465,  257,  290,  257,  262,  357]),\n",
       "  tensor([  286,   339, 12036,  5527,  4920,  4489, 34686, 10915])]]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_batch = next(data_itre)\n",
    "second_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(100)\n",
    "input_ids = torch.tensor([2,3,3,5])\n",
    "vocab_size = 6 \n",
    "output_dim = 3\n",
    "embedding_layer = torch.nn.Embedding(vocab_size,output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1268,  1.3564, -0.0247],\n",
      "        [-0.8466,  0.0293, -0.5721],\n",
      "        [-1.2546,  0.0486,  0.2753],\n",
      "        [-2.1550, -0.7116,  0.0575],\n",
      "        [ 0.6263, -1.7736, -0.2205],\n",
      "        [ 2.7467, -1.0480,  1.1239]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1550, -0.7116,  0.0575]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "“If we compare the embedding vector for token ID 3 to the previous embedding matrix, we see that it is identical to the 4th row (Python starts with a zero index, so it's the row corresponding to index 3). \n",
    "In other words, the embedding layer is essentially a look-up operation that retrieves rows from the embedding layer's weight matrix via a token ID.”\n",
    "\n",
    "\n",
    "'''\n",
    "embedding_layer(torch.tensor([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2546,  0.0486,  0.2753],\n",
       "        [-2.1550, -0.7116,  0.0575],\n",
       "        [-2.1550, -0.7116,  0.0575],\n",
       "        [ 2.7467, -1.0480,  1.1239]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"“Figure 2.16 Embedding layers perform a look-up operation, retrieving the embedding vector corresponding to the token ID from the embedding layer's weight matrix. \\nFor instance, the embedding vector of the token ID 5 is the sixth row of the embedding layer weight matrix (it is the sixth instead of the fifth row because Python starts counting at 0). \\nFor illustration purposes, we assume that the token IDs were produced by the small vocabulary we used in section 2.3.\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''“Figure 2.16 Embedding layers perform a look-up operation, retrieving the embedding vector corresponding to the token ID from the embedding layer's weight matrix. \n",
    "For instance, the embedding vector of the token ID 5 is the sixth row of the embedding layer weight matrix (it is the sixth instead of the fifth row because Python starts counting at 0). \n",
    "For illustration purposes, we assume that the token IDs were produced by the small vocabulary we used in section 2.3.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nEncoding word positions \\nconverted token ids into embedding , In principle this is a suitable input for an LLM. However a minor shortcoming of llms is that their self attention mechanism . doesn't have the nnotion of position or order for the order for the position\\nwithin a sequence \\n\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Encoding word positions \n",
    "converted token ids into embedding , In principle this is a suitable input for an LLM. However a minor shortcoming of llms is that their self attention mechanism . doesn't have the notion of position or order for the order for the position\n",
    "within a sequence \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
